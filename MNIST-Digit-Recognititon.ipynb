{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognition Lab ðŸ¥¼ðŸ¤–\n",
    "\n",
    "George Bennett ~ June 6, 2023\n",
    "\n",
    "* Goal: Create a model to classify 28x28 pixel images of hand-written digits\n",
    "* Value: Good practice\n",
    "* This work is based off of this <a href=\"https://www.youtube.com/watch?v=bte8Er0QhDg\">youtube video</a> by <a href=\"https://www.youtube.com/@NeuralNine\">NeuralNine</a>\n",
    "* The dataset I'll be working with is MNIST or the <a href=\"https://en.wikipedia.org/wiki/MNIST_database\">Modified National Institute of Standards and Technology database</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "np.random.seed(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll retrieve the data. The MNIST Dataset can be imported directly from tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second I'll split the data into a train group and a test group. The test group acts as a control and provides an example of how well the model will work on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly I'll normalize the data. This means that every* pixel value will be between 0 and 1 instead of the original 0 to 255.<br>\n",
    "<sub><sub>*Unseen data may be slightly higher or lower</sub></sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourthly I'll build the model:\n",
    "\n",
    "* Sequential means that it is a one directional flow of connections <br>\n",
    "* The flatten layer simply takes the 28x28 2D pixel matrix and turns it into a ${28}^2$ long 1D list of values <br>\n",
    "* The dense layer is a layer of neurons that is connected to every neuron in the layer before it and the layer after it. It is the default. <br>\n",
    "* The 'relu' activation function stands for 'Rectified Linear Unit'. This simply means that the neuron only fires if it has a positive value and it fires with a strength proportional to that value.<br>\n",
    "* The 'softmax' activation function is used for categorization. I'm giving this layer 10 neurons because there are 10 answers it has to choose from. All the values in the softmax layer sum up to 1 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the neural net\n",
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(layer = tf.keras.layers.Flatten())\n",
    "model1.add(layer = tf.keras.layers.Dense(128, activation='relu'))\n",
    "model1.add(layer = tf.keras.layers.Dense(128, activation='relu'))\n",
    "model1.add(layer = tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been built I will train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2652 - accuracy: 0.9221\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1079 - accuracy: 0.9664\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0728 - accuracy: 0.9773\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0545 - accuracy: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe257dd150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the neural net\n",
    "model1.fit(x_train, y_train, epochs=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to see how well the model did on the training data. If satisfactory we can finalize this lab and review the results on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0385 - accuracy: 0.9875\n",
      "0.03849118947982788 0.9874500036239624\n"
     ]
    }
   ],
   "source": [
    "# training results\n",
    "loss, accuracy = model1.evaluate(x_train, y_train)\n",
    "print(loss, accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieved 99% accuracy on the training set (ðŸŽ‰). The last step is to see the test results. Once the test results have been viewed, it will be bad practice to take this lab any further as I would be introducing bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0899 - accuracy: 0.9742\n",
      "0.08988400548696518 0.9742000102996826\n"
     ]
    }
   ],
   "source": [
    "# test results\n",
    "loss, accuracy = model1.evaluate(x_test, y_test)\n",
    "print(loss, accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab complete! The model is ready for production. ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist-model-1-v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist-model-1-v1\\assets\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "model1.save(\"mnist-model-1-v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
